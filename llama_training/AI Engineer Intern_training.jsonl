{"instruction": "Given the following job description, create a tailored resume:\n\nJob Title: AI Engineer Intern\n\nJob Description:\nAbout Tanagram:\nTanagram's mission is to enable developers to work at the speed of thought. To do that, we're building a tool that captures hard-won lessons buried in codebases, code reviews, incident post-mortems, and Slack chats. We turn those lessons into real-time guardrails that flag or fix risky patterns the moment they reach a pull request \u2014 and, eventually, at code generation time \u2014 so that engineers can ship faster and avoid disaster.\nImagine an ideal staff engineer. They know the entire codebase and how different systems interact. They follow every PR, so they know what changes are being made and how patterns evolve. They've read all the documentation. They keep up-to-date on Slack conversations. Ultimately, they index all that information in their heads, and deliver impact by showing up everywhere and saying the right things at the right time.\nWe're building that, but at scale for entire teams and companies. Tanagram is an extension of every team's best staff engineer, available anywhere and anytime.\nAbout This Role:\nAs an AI Engineer Intern, you'll bridge the gap between AI research and application by using the latest research and models to build our product end-to-end. Currently, our product is almost entirely backend; we do not yet have a UI (although we will start building a UI for our product soon). We mostly build in Python, with some Swift for CPU-bound operations.\nWe\u2019re a small team of generalists and work across multiple domains. We're looking for meticulous, high-agency people who have the skills (or learning ability) to solve problems expediently, and an understanding of the appropriate quality bar given the surrounding business context.\nWe will generally work in-person in San Francisco (our office is in Mission Bay).\nWhat You Might Do:\nTalk directly to users: understand their requirements, ask for their feedback, follow up as needed, and iterate based on what they say.\nEvaluate and build with the best tools in an AI agentic stack: LLM-Evals, Guardrails for AI, CodeAct (agents writing code), memory for agents (like Mem0).\nBuild services to ingest data from places like Github, Slack, and Confluence.\nDeploy & use reasoning models like Qwen2.5-7B-Instruct.\nEagerly identify and implement improvements to our core foundations (e.g. clearing performance bottlenecks for scalability).\nEnsure that systems are efficient, maintainable, and well-monitored.\nWhat We Offer:\nChallenging work with the latest advances in LLM techniques.\nTop-of-market compensation.\nComputer/office equipment stipend.\nFood stipend/reimbursements on meals.\nHealth, dental, and vision insurance.\nUnlimited PTO.\nA relatively un-chaotic working environment (we aren't pivoting every week).\nAn opportunity to help define our company.\nQualifications:\nHands-on experience building with LLMs, with a strong intuition for what models can do and how to get the best results out of them.\nWell-crafted (i.e. generally reliable; tastefully designed) work examples.\nSelf-direction and motivation: you repeatedly, independently seek out the most valuable thing you could be doing, and start working on it. You do so even when requirements and priorities may be changing rapidly.\nDecisive, clear communication on both technical and strategic matters: at this stage, you'll be helping build the foundations of our company. You should have ideas/opinions about almost everything we do, and you should be forthcoming with your thoughts (even if it means being disagreeable).\nBonus points:\nExperience working on parsers and compilers (e.g. LLVM; Typescript), type systems (e.g. Sorbet), or VSCode or IntelliJ itself.\nExperience with search and/or indexing technologies.\nIf you've previously worked at a startup, or founded one yourself.\nCompensation:\nDepending on the relevance and amount of your experience, the salary for this position ranges from $2,000 to $2,500 per week.\n\nPlease create a tailored resume that highlights relevant skills and experience for this position.", "input": "", "output": "Here is a tailored resume for the AI Engineer Intern position:\n\nSATHVIK ADDICHARLA\nDenton, TX 76207 | sathvikaddicharla@my.unt.edu | +1 (940) 597-5745 | [GitHub] | [LinkedIn]\nPROFESSIONAL SUMMARY\nAI Engineer experienced in building intelligent backend systems with LLMs, agent-based pipelines, and real-time inference APIs. Hands-on with LangChain, OpenAI, Hugging Face, and FAISS for deploying retrieval-augmented systems. Proven ability to work autonomously and rapidly iterate on backend services integrating source control tools (GitHub), chat systems (Slack), and custom embeddings. Passionate about building developer tools that scale insights and reduce friction at the point of code.\nTECHNICAL SKILLS\nLLMs & Agents: LangChain, OpenAI (GPT-4, Whisper), Hugging Face Transformers, Prompt Engineering\nRetrieval & Memory: FAISS, Vector DBs, LangGraph, RAG, Guardrails for AI (familiar)\nBackend & DevOps: Flask, FastAPI, REST, Docker, MLflow, GitHub API, Git\nData Sources & Integration: GitHub, Slack, Google Docs API, JSON config pipelines\nProgramming: Python (advanced), C++ (intermediate), Bash, SQL\nInfrastructure: AWS (Lambda, S3), Linux, Modular ML pipeline architecture\nOther: Self-documenting code, reproducibility, async collaboration (Slack, Figma, Google Meet)\nEDUCATION\nMaster\u2019s in Data Science\nUniversity of North Texas | 04/2024 \u2013 08/2026 | GPA: 3.66/4.0\nBachelor\u2019s in Computer Science \u2013 Data Science\nVNR Vignana Jyothi Institute of Technology, India | GPA: 8.60/10\nEXPERIENCE\nAI/ML Engineer Intern\nCantellate Software Pvt Ltd | Hyderabad | 03/2023 \u2013 09/2023\nDeveloped a LangChain-powered assistant with memory-enabled retrieval from GitHub wikis, chat logs, and internal documents.\nDeployed API-driven NLP agents on AWS with Docker; performance-tuned using MLflow and prompt refinements.\nCreated self-contained modular services with JSON-configured logic blocks to enable fast experimentation and reproducibility.\nCollaborated cross-functionally with engineers and analysts in an async workflow to deliver daily deployable updates.\nOptimized latency in agent chains by tuning vector search (FAISS) and token windowing logic.\nPROJECTS\nCode-Aware LLM Chatbot (LangChain + OpenAI)\nBuilt a GPT-style coding assistant to retrieve and reference inline documentation and engineering practices across GitHub PRs and Slack chats.\nUsed RAG + LangGraph architecture to chain context-aware agents; engineered guardrails for source-specific validation.\nSemantic AI Summarizer (Whisper + FAISS)\nDeveloped OpenAI Whisper-based transcription system with vector search over semantic embeddings for topic-specific summarization.\nFocused on backend orchestration and latency optimization in concurrent agent calls.\nSpeech Emotion Recognition via Configurable LSTM APIs\nContainerized deep learning model using MFCC preprocessing and FastAPI for minimal endpoint exposure; designed with JSON configurability.\nCERTIFICATIONS & TRAINING\nTraining LLMs with Your Own Data \u2013 DeepLearning.ai\nDeep Learning \u2013 NPTEL (IIT Ropar)\nPython for Data Science \u2013 Udemy\nGoogle Data Analytics \u2013 Coursera\nPUBLICATIONS\nRAG-Based LLM Chatbot for Diagnosing Health Conditions \u2013 IEEE (09/2024)\nTransfer Learning for Autism Detection in Children \u2013 IEEE (08/2024)"}
