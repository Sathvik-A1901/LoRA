{"instruction": "Given the following job description, create a tailored resume:\n\nJob Title: Machine Learning Engineer\n\nJob Description:\nAbout the job\nOur vision is to transform how the world uses information to enrich life for all.\nMicron Technology is a world leader in innovating memory and storage solutions that accelerate the transformation of information into intelligence, inspiring the world to learn, communicate and advance faster than ever.\nAs a machine learning engineer in Micron's Scalable Memory Systems group, you will be part of a pathfinding and strategy organization that is defining and influencing the future direction of memory for high-performance compute (HPC) and artificial intelligence (AI) systems!\nIn this role, you will apply and grow your expertise in machine learning (ML), AI software workflows and compute system architecture. You will support technology pathfinding needs which may include AI research, analyzing use cases, exploring tools, benchmarking performance, and collaborating with others. You will have an opportunity to work with proof-of-concept computer systems comprising multiple host servers, GPUs, shared memory and memory accelerators!\nThis hybrid work schedule position is located in Richardson, TX.\nYour Responsibilities May Include, But Are Not Limited To\nResearching technologies and tools related to ML and AI\nDeveloping and analyzing AI workflows to support use case studies\nCollaborating with system architects and software engineers to define and influence memory innovations for future compute systems\nModifying applications and libraries for technology demonstrations\nSharing knowledge with others through white papers and presentations\nWe Are Seeking Candidates With The Following\n(Required) PhD, master\u2019s degree with \u22655 years\u2019 relevant experience, or bachelor\u2019s degree with \u226510 years\u2019 relevant experience\n(Required) Experience implementing AI workflows using AI/ML frameworks (PyTorch, TensorFlow, etc.)\n(Required) Deep technical understanding of ML and AI algorithms, neural networks and models\nKnowledge of how compute system architecture and memory scaling impact AI and ML workflows and models\nExperience with application performance benchmarking on heterogeneous (CPU + GPU) systems\nExperience programming GPUs (CUDA, OpenCL, SYCL, etc.)\nPython and C++ programming experience in a Linux environment\nFamiliarity with compute scaling, parallel computing and shared memory technologies (CXL, NvLink, UALink, OpenMP, MPI, etc.) is desired\nWillingness to work on a varying mix of research- and demonstration-focused assignments depending on the changing needs of a pathfinding organization\nAbility to work in a team environment that includes both on-site and remote team members\n#hybrid\nAs a world leader in the semiconductor industry, Micron is dedicated to your personal wellbeing and professional growth. Micron benefits are designed to help you stay well, provide peace of mind and help you prepare for the future. We offer a choice of medical, dental and vision plans in all locations enabling team members to select the plans that best meet their family healthcare needs and budget. Micron also provides benefit programs that help protect your income if you are unable to work due to illness or injury, and paid family leave. Additionally, Micron benefits include a robust paid time-off program and paid holidays. For additional information regarding the Benefit programs available, please see the Benefits Guide posted on micron.com/careers/benefits.\nMicron is proud to be an equal opportunity workplace and is an affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, citizenship status, disability, protected veteran status, gender identity or any other factor protected by applicable federal, state, or local laws.\nTo learn about your right to work click here.\nTo learn more about Micron, please visit micron.com/careers\nFor US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron\u2019s People Organization at hrsupport_na@micron.com or 1-800-336-8918 (select option #3)\nMicron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.\nMicron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron.\n\nPlease create a tailored resume that highlights relevant skills and experience for this position.", "input": "", "output": "Here is a tailored resume for the Machine Learning Engineer position:\n\nSATHVIK ADDICHARLA\nDenton, TX 76207 | sathvikaddicharla@my.unt.edu | +1 (940) 597-5745 | [LinkedIn] | [GitHub]\nPROFESSIONAL SUMMARY\nMachine Learning engineer with strong research experience in scalable AI workflows and system-level performance optimization. Proficient in PyTorch, TensorFlow, and transformer-based models with practical exposure to GPU-based computing, benchmarking, and MLOps. Published in IEEE for work on LLMs and retrieval systems. Skilled in C++/Python in Linux environments and passionate about contributing to memory-optimized AI computing systems.\nTECHNICAL SKILLS\nFrameworks: PyTorch, TensorFlow, Keras, Hugging Face Transformers\nSystem & Performance: CUDA (familiar), TorchScript, Quantization, ONNX, Benchmarking\nParallel/Shared Memory: OpenMP, FAISS, MPI (familiar), CXL/NvLink (conceptual knowledge)\nLanguages: Python, C++\nTooling & Infra: MLflow, Docker, Git, FastAPI, AWS, Linux\nResearch & Workflow Analysis: Literature Review, Prompt Evaluation, Profiling\nEDUCATION\nMaster\u2019s in Data Science\nUniversity of North Texas | 04/2024 \u2013 08/2026 | GPA: 3.66/4.0\nBachelor\u2019s in Computer Science \u2013 Data Science\nVNR Vignana Jyothi Institute of Technology, India | GPA: 8.60/10\nEXPERIENCE\nAI/ML Engineer Intern\nCantellate Software Pvt Ltd | Hyderabad, India | 03/2023 \u2013 09/2023\nBuilt scalable ML workflows for real-time fraud detection using PyTorch with <100ms latency, benchmarked across cloud GPU environments.\nDeveloped and deployed transformer-based models with quantized inference, reducing model size and accelerating performance by 40%.\nManaged end-to-end ML lifecycle (500GB+ data), deployed systems on AWS, and monitored using MLflow.\nIntegrated OpenAI APIs with LLM evaluation workflows; tuned prompts using statistical profiling and chain-of-thought reasoning.\nCollaborated across data engineering and system teams to support optimization of shared memory resource utilization.\nPROJECTS\nHigh-Performance RAG Chatbot (LangChain + Hugging Face)\nBuilt scalable NLP pipeline integrating vector database (FAISS) and GPT-based model for real-time health diagnostics.\nConducted evaluation and performance profiling of retrieval vs generation latency, published in IEEE.\nAI Summarizer with Whisper + FAISS\nOptimized OpenAI Whisper transcriptions and semantic retrieval with FAISS; tested on GPU for throughput analysis.\nAchieved 92% relevance accuracy and 75% reduction in summarization time.\nSpeech Emotion Detection (LSTM + CUDA Concepts)\nDesigned LSTM-based speech classifier with MFCC preprocessing.\nApplied CUDA-aware optimization concepts for mini-batch audio processing in PyTorch.\nCERTIFICATIONS & TRAINING\nDeep Learning \u2013 NPTEL (IIT Ropar)\nPython for Data Science \u2013 Udemy\nTraining LLMs with Your Own Data \u2013 DeepLearning.ai\nGoogle Data Analytics \u2013 Coursera\nPUBLICATIONS\nRetrieval-Augmented Generation Chatbot for Medical Use Cases \u2013 IEEE (09/2024)\nTransfer Learning-Based Autism Detection in Children \u2013 IEEE (08/2024)"}
