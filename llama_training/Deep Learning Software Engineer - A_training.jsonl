{"instruction": "Given the following job description, create a tailored resume:\n\nJob Title: Deep Learning Software Engineer - AI Models\n\nJob Description:\nAbout the job\nWHAT YOU DO AT AMD CHANGES EVERYTHING\nWe care deeply about transforming lives with AMD technology to enrich our industry, our communities, and the world. Our mission is to build great products that accelerate next-generation computing experiences - the building blocks for the data center, artificial intelligence, PCs, gaming and embedded. Underpinning our mission is the AMD culture. We push the limits of innovation to solve the world\u2019s most important challenges. We strive for execution excellence while being direct, humble, collaborative, and inclusive of diverse perspectives.\nAMD together we advance_\nThe Role\nAMD is looking for a software engineer who is passionate about expanding AI models on AMD GPUs, and improving the performance of key applications and benchmarks. You will be a member of a core team of incredibly talented industry specialists and will work with the very latest hardware and software technology.\nThe Person\nStrong technical and analytical skills in C++/Python AI development in a Linux environment. Ability to work as part of a team, while also being able to work independently, define goals and scope and lead your own development effort.\nKey Responsibilities\nEnable and optimize key AI models (LLM, Vision, MultiModal, etc.) on AMD GPUs\nOptimize AI frameworks like PyTorch, TensorFlow, etc. on AMD GPUs in upstream open-source repositories\nCollaborate and interact with internal GPU library teams to analyze and optimize training and inference for AI\nWork with open-source framework maintainers to understand their requirements - and have your code changes integrated upstream\nOptimize GPU kernels, understand and drive AI operator performance (GEMM, Attention, etc.) with specialized teams\nWork in a distributed computing setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems\nApply your knowledge of software engineering best practices\nPreferred Experience\nKnowledge of GPU computing (HIP, CUDA, OpenCL)\nAI model experience or knowledge - Natural Language Processing, Vision, Audio, Recommendation systems\nExcellent C/C++/Python programming and software design skills, including debugging, performance analysis, and test design.\nExperiences to run workloads on large scale heterogeneous cluster is a plus\nExperiences to optimize GPU kernels for performance is a plus\nAcademic Credentials\nMasters or PhD or equivalent experience in Computer Science, Computer Engineering, or related field\nBenefits offered are described: AMD benefits at a glance.\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants\u2019 needs under the respective laws throughout all stages of the recruitment and selection process.\n\nPlease create a tailored resume that highlights relevant skills and experience for this position.", "input": "", "output": "Here is a tailored resume for the Deep Learning Software Engineer - AI Models position:\n\nSATHVIK ADDICHARLA\nDenton, TX 76207 | sathvikaddicharla@my.unt.edu | +1 (940) 597-5745 | [LinkedIn] | [GitHub]\nPROFESSIONAL SUMMARY\nDeep Learning engineer with expertise in LLMs, computer vision, and audio-based models, optimized for cloud and GPU environments. Experience with PyTorch and TensorFlow model deployment and performance tuning. Proficient in Python and C++ with a focus on distributed inference, quantization, and kernel-aware optimization. Passionate about AI acceleration at the systems level and contributing to open-source AI frameworks that scale across GPU hardware stacks.\nTECHNICAL SKILLS\nAI Frameworks: PyTorch, TensorFlow, Keras, Hugging Face Transformers\nGPU Programming & Optimization: ONNX, TorchScript, CUDA (basic), HIP (learning), GEMM ops, Kernel tuning concepts\nLanguages: Python, C++, SQL\nSystem Performance & Scaling: Docker, MLflow, OpenMP (familiar), Linux, multi-GPU pipeline experience\nAI Models: LLMs (RAG, GPT-style), Vision (OpenCV), Speech (Whisper, MFCC), Multimodal Chatbots\nDistributed Infra: AWS, GCP (Vertex AI), LangChain, FAISS, FastAPI, REST APIs\nOpen Source Workflows: GitHub, Hugging Face, LangGraph, MLflow\nEDUCATION\nMaster\u2019s in Data Science\nUniversity of North Texas | 04/2024 \u2013 08/2026 | GPA: 3.66/4.0\nBachelor\u2019s in Computer Science \u2013 Data Science\nVNR Vignana Jyothi Institute of Technology, India | GPA: 8.60/10\nEXPERIENCE\nAI/ML Engineer Intern\nCantellate Software Pvt Ltd | Hyderabad, India | 03/2023 \u2013 09/2023\nDeployed and optimized PyTorch-based models on GPU for real-time fraud detection, achieving sub-100ms inference and ~85% accuracy.\nConverted models to ONNX and optimized TorchScript flows for inference tuning; collaborated with cloud infra for deployment on GPU clusters.\nBuilt LLM-based retrieval assistant using Hugging Face, FAISS, and LangChain; reduced latency by 50% through quantized vector indexing.\nIntegrated ML models into full production stack: Docker, REST API, MLflow tracking, and logging on Linux.\nApplied profiling to transformer blocks and memory usage to identify bottlenecks during batch inference.\nPROJECTS\nLLM Chatbot for Diagnostics (IEEE Published)\nTrained and evaluated transformer-based chatbot using LangChain + FAISS retrieval on medical QA datasets.\nUsed LangGraph and custom prompt flows to optimize GPU-bound memory and retrieval latency.\nAI Summarizer (Whisper + Transformers + FAISS)\nImplemented multimodal summarizer using Whisper transcription + FAISS-based vector similarity for content matching.\nTested inference time across local GPU and cloud setups, achieving ~92% relevance accuracy.\nSpeech Emotion Recognition (LSTM + MFCC + GPU)\nBuilt emotion classifier from audio features, parallelized mini-batch training for GPU acceleration using PyTorch.\nCERTIFICATIONS & TRAINING\nDeep Learning \u2013 NPTEL (IIT Ropar)\nTraining LLMs with Your Own Data \u2013 DeepLearning.ai\nPython for Data Science and Machine Learning \u2013 Udemy\nGoogle Data Analytics \u2013 Coursera\nPUBLICATIONS\nGPU-Enhanced RAG-Based LLM Chatbot for Diagnosis \u2013 IEEE (09/2024)\nTransfer Learning for Autism Detection in Children \u2013 IEEE (08/2024)"}
