{"instruction": "Given the following job description, create a tailored resume:\n\nJob Title: Machine Learning Engineering Intern\n\nJob Description:\nAbout the job\nJob Overview\nWe are seeking a passionate and highly motivated Machine Learning Engineer Intern to join our Machine Learning Team. This internship offers hands-on experience working with cutting-edge transformer-based deep learning models including XLNet, T5, and ELECTRA. The intern will contribute to optimizing model inference performance, managing the end-to-end ML model lifecycle, and supporting deployment workflows. As an intern you'll gain practical experience in managing and deploying real-world ML models. Mentorship from experienced ML engineers. Exposure to MLOps best practices and scalable deployment frameworks, and an Opportunity to contribute to high-impact projects that improve real-world systems.\nJob Responsibilities\nOptimize inference performance for transformer-based models (e.g., quantization, pruning, batch inference).\nDesign and implement workflows for managing the model lifecycle (training, versioning, deployment, and monitoring).\nConduct performance benchmarking and develop tools to analyze and visualize model performance.\nCollaborate with engineers and researchers to implement scalable and efficient model serving solutions.\nSupport integration of ML models into production pipelines using industry-standard tools and frameworks.\nJob Requirements\nCurrently pursuing a Master\u2019s or Ph.D. in Computer Science, Machine Learning, or a related field.\nStrong foundation in deep learning and hands-on experience with transformer architectures.\nProficiency in Python and experience with ML frameworks such as PyTorch or TensorFlow.\nFamiliarity with model optimization techniques (e.g., ONNX, TorchScript, quantization).\nExposure to model versioning and lifecycle tools (e.g., MLflow, SageMaker, or similar).\nStrong problem-solving skills and ability to work in a collaborative environment.\nExperience with containerization (Docker), orchestration tools (Kubernetes), or cloud platforms (AWS/GCP/Azure).\nUnderstanding of distributed training/inference strategies.\nWhy Work With Us?\nWhen you work with Cambium Assessment, you\u2019ll be helping to design and build inspiring solutions that make a real impact on the online testing industry, as well as the educators and students we support.\nOur Ground Breaking Work Includes\nAdvanced computer-adaptive algorithms\nMobile support of user interfaces\nLearning management systems with social media features\nUniversally accessible user interfaces\nMachine scorable items\nIn the 2024 school year, we delivered more than 126 million online tests, and successfully supported peak testing volumes exceeding 1.5 million simultaneous test takers. We have the most advanced features of any online testing system, and we continue to push boundaries to improve student performance measurement and enabling educators with actionable insights to drive better overall educational outcomes for our students. To learn more about our organization and the exciting work we do, visit www.cambiumassessment.com.\nRemote First Work Environment\nOur Remote First approach gives employees the flexibility and trust they need to effectively balance work with life. It creates a culture in which all employees are valued and where success is measured in results. It allows us to work collaboratively, inclusively and for greater positive impact, regardless of our individual locations.\nIf you will be working remotely, either occasionally or on a permanent basis, you must have a reliable internet connection through a cable or fiber-optic broadband service with minimum speeds of 10 Mbps download and 5 Mbps upload.\nThe successful candidate will be expected to actively participate in video-based interviews during the recruiting process and ongoing virtual meetings with their camera on, as part of their role.\nAs part of our Remote-First benefits, Cambium offers reimbursement to help cover the cost of setting up your home or remote office.\nAn Equal Opportunity Employer\nWe are dedicated to fostering a culture that celebrates unique backgrounds, ideas, and experiences. All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, age, religion, sex (including pregnancy, gender, gender identity/expression, or sexual orientation), national origin, protected veteran status, disability, or genetic information (including family medical history).\nWe will provide reasonable accommodations for qualified individuals with disabilities. You may request an accommodation during the recruiting process with your Talent Acquisition team member.\nRESUME\nSATHVIK ADDICHARLA\nDenton, TX 76207 | sathvikaddicharla@gmail.com | +1 (940) 597-5745 | LinkedIn | GitHub\nPROFESSIONAL SUMMARY\nMachine Learning graduate student with hands-on experience building and deploying scalable ML models for real-time applications in NLP and computer vision. Skilled in transformer-based architectures (e.g., Hugging Face, RAG), MLOps workflows using MLflow and Docker, and performance optimization (e.g., quantization, TorchServe). Proven ability to manage the full ML lifecycle from preprocessing to cloud deployment. Passionate about contributing to production-level ML systems with a focus on scalable deployment and system performance.\nTECHNICAL SKILLS\nML Frameworks: PyTorch, TensorFlow, Hugging Face Transformers, MLflow, Keras\nTransformer Models: BERT, T5, RAG, ELECTRA (via Hugging Face), Whisper\nModel Optimization: TorchServe, TorchScript, Quantization, Pruning, ONNX (familiar)\nMLOps Tools: Docker, Flask, REST API, AWS S3, MLflow\nData Handling: Pandas, NumPy, OpenCV, Seaborn, Matplotlib\nProgramming Languages: Python, C++, SQL\nCloud/Infra: AWS (S3, Lambda), Familiarity with GCP/Azure, HPC concepts\nOther Tools: FAISS, Hadoop, Git, Jupyter, Visual Studio Code\nEDUCATION\nMaster\u2019s in Data Science\nUniversity of North Texas | 04/2024 \u2013 08/2026 | GPA: 3.66/4.0\nBachelor\u2019s in Computer Science \u2013 Data Science\nVNR Vignana Jyothi Institute of Technology, India | GPA: 8.60/10\nEXPERIENCE\nAI/ML Engineer Intern\nCantellate Software Pvt Ltd | J-HUB, JNTU-Hyderabad, India | 03/2023 - 09/2023\nBuilt and deployed ML models (PyTorch) with quantized inference, improving prediction accuracy by 85% and reducing latency by 40%.\nManaged end-to-end ML lifecycle: data cleaning (500GB+), training, model versioning (MLflow), and real-time cloud deployment (AWS).\nIntegrated RAG-powered question-answering models using Hugging Face Transformers and LangChain, improving NLP performance by 75%.\nCreated fraud detection systems with 95% detection accuracy and sub-100ms inference, optimized using TorchServe.\nSupported MLOps workflows including containerization via Docker and RESTful API deployment for seamless model serving.\nPROJECTS\nRAG-Based LLM Chatbot for Health Diagnostics\nDeveloped NLP-based chatbot using RAG architecture and LangChain to deliver accurate health diagnostics with real-time document retrieval.\nImplemented model evaluation, visualization, and performance tuning using statistical metrics and MLflow logging.\nPublished in IEEE (09/2024).\nYouTube Summarizer using Whisper and FAISS\nCreated summarizer pipeline using OpenAI Whisper for transcription, Transformers for embedding, and FAISS for semantic retrieval.\nAchieved 92% relevance in response generation and reduced content processing time by 75%.\nTech Stack: Whisper, FAISS, Python, Hugging Face, Flask\nCERTIFICATIONS & TRAINING\nDeep Learning \u2013 NPTEL (IIT Ropar)\nPython for Data Science and ML \u2013 Udemy\nTraining LLMs with Own Data \u2013 DeepLearning.ai\nGoogle Data Analytics \u2013 Coursera\nPUBLICATIONS\nRAG-Based LLM Chatbot for Improving Diagnosis of Physical and Mental Health \u2013 IEEE (09/2024)\nTransfer Learning for Autism Detection in Children \u2013 IEEE (08/2024)\n\nPlease create a tailored resume that highlights relevant skills and experience for this position.", "input": "", "output": "Here is a tailored resume for the Machine Learning Engineering Intern position:\n\n"}
