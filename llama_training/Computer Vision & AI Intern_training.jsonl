{"instruction": "Given the following job description, create a tailored resume:\n\nJob Title: Computer Vision & AI Intern\n\nJob Description:\nAbout Krevera\nKrevera builds AI-powered vision systems that spot defects on the factory floor before scrap happens. Our deep-learning pipelines detect anomalies in real-time, diagnose root causes, and feed insights back to injection-molding machines and robotics so that quality issues are fixed automatically.\nWe are a VC-backed startup (pre-seed raised) with our first paying customers and a clear path to scale.\nOverview\nAs a Computer Vision & AI Intern, you'll support Krevera\u2019s AI development team in building and refining our data-to-deployment pipeline. You'll gain hands-on experience with data collection, model training, testing, and deploying machine learning models to edge devices. You'll work closely with our team on multi-view vision transformers, Vision-Language Models (VLMs), and real-time inference systems.\nKey Responsibilities\nAssist with data pipeline activities, including data collection, preprocessing, and synthetic data generation.\nSupport training and validation of state-of-the-art models (multi-view ViTs, VLMs) for real-time defect detection.\nHelp evaluate and optimize models for edge deployment, meeting performance targets.\nLearn and apply MLOps best practices, including model versioning, monitoring, and CI/CD workflows.\nCollaborate actively with the Simulation and Software Engineering teams to align project deliverables with team objectives.\nWhat We\u2019re Looking For\nA curious learner with a passion for AI, eager to contribute and grow in a supportive, fast-paced environment.\nA strong communicator who enjoys working collaboratively across disciplines.\nA proactive problem solver excited to tackle real-world engineering challenges.\nSkills & Tools\nPython and C++ programming proficiency; you write clean, maintainable, and efficient code.\nFamiliarity with or coursework in ROS 2 and OpenCV, especially for real-time inference applications.\nHands-on experience with PyTorch, and comfortable building and training deep neural networks.\nKnowledge or academic experience with multi-view Vision Transformers and/or Vision-Language Models (VLMs).\nExposure to or coursework in distributed cloud computing using platforms such as Ray (Anyscale).\nFamiliarity with cloud environments, particularly AWS (EKS/Kubernetes, S3) or similar technologies.\nWhy Krevera\nCollaborative, fun, innovative culture: Enjoy a startup environment with a flat hierarchy where teamwork and creativity thrive\u2014whether brainstorming ideas, playing occasional video games over lunch, or taking company walks.\nReal impact: Your contributions will directly influence products used by real customers.\nFront-row seat to AI in manufacturing: Engage with cutting-edge technologies shaping the future of industrial AI.\nMomentum & resources: Fresh off a venture-capital raise and 12 months of booked contracts, we have runway and customers eager for our models. We are well funded and moving fast!\nLogistics\nLocation: On-site, Waltham, MA.\nStart date: Flexible; positions available immediately and throughout the year.\n\nPlease create a tailored resume that highlights relevant skills and experience for this position.", "input": "", "output": "Here is a tailored resume for the Computer Vision & AI Intern position:\n\nSATHVIK ADDICHARLA\nDenton, TX 76207 | sathvikaddicharla@my.unt.edu | +1 (940) 597-5745 | [GitHub] | [LinkedIn]\nPROFESSIONAL SUMMARY\nAI Engineer with experience developing real-time, production-grade ML systems using PyTorch, OpenCV, and Transformers. Skilled in model training, inference optimization, and pipeline deployment with a strong emphasis on performance and reproducibility. Hands-on with LLMs, speech/vision models, MLOps tools, and edge-aware containerized deployment. Passionate about building defect-tolerant systems and collaborating cross-functionally in fast-paced startup environments.\nTECHNICAL SKILLS\nComputer Vision & AI: OpenCV, PyTorch, Vision Transformers (ViT \u2013 academic), LangChain, Whisper\nProgramming: Python (advanced), C++ (intermediate), Bash, SQL\nMLOps & Deployment: Docker, MLflow, AWS (S3, Lambda), CI/CD (familiar), GitHub\nCloud & Scaling: AWS, Ray (introductory knowledge), REST APIs, EKS (learning)\nData Pipeline & Modeling: Data preprocessing, synthetic data handling, inference tuning\nOther Tools: ROS2 (course familiarity), Hugging Face, JSON config workflows, LangGraph\nEDUCATION\nMaster\u2019s in Data Science\nUniversity of North Texas | 04/2024 \u2013 08/2026 | GPA: 3.66/4.0\nBachelor\u2019s in Computer Science \u2013 Data Science\nVNR Vignana Jyothi Institute of Technology, India | GPA: 8.60/10\nEXPERIENCE\nAI/ML Engineer Intern\nCantellate Software Pvt Ltd | Hyderabad | 03/2023 \u2013 09/2023\nBuilt fraud detection system with real-time inference (<100ms), optimized PyTorch pipelines for production use.\nIntegrated LangChain and Hugging Face Transformers into a RAG system; deployed with Docker + REST API.\nCreated a modular ML pipeline using MLflow for versioning, reproducibility, and tuning across environments.\nUsed OpenCV and Whisper for audio-visual emotion classification, with focus on low-latency performance.\nCollaborated across software and ML teams to align training outputs with deployment edge constraints.\nPROJECTS\nVision-Based Summarizer (Whisper + OpenCV + FAISS)\nDesigned a video summarization pipeline using Whisper + semantic segmentation with OpenCV visual markers.\nBuilt for real-time parsing of streaming content with API-level retrieval and performance monitoring.\nDiagnostic Chatbot using RAG + Transformers (IEEE Publication)\nCreated a real-time NLP assistant with LangGraph & LangChain integrating health symptom data; handled multi-modal queries.\nFocused on embedding pipelines, fast tokenized input handling, and semantic indexing.\nSpeech Emotion Recognition using MFCC + LSTM\nTrained model to classify speech emotion from audio; fine-tuned attention-based architecture and deployed via Flask.\nEvaluated across noisy, real-world datasets to mimic edge environments with constrained input.\nCERTIFICATIONS & TRAINING\nDeep Learning \u2013 NPTEL (IIT Ropar)\nTraining LLMs with Your Own Data \u2013 DeepLearning.ai\nPython for Data Science \u2013 Udemy\nGoogle Data Analytics \u2013 Coursera\nPUBLICATIONS\nRAG-Based Diagnostic Chatbot with LangChain & Transformers \u2013 IEEE (09/2024)\nTransfer Learning for Autism Detection from Audio \u2013 IEEE (08/2024)"}
